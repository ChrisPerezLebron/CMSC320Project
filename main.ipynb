{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import matplotlib as plt\n",
    "\n",
    "df = pd.read_csv(\"Walmart_sales.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Date column into date time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df['Date'], format=\"%d-%m-%Y\")\n",
    "\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Feature Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a look at the number of stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numStores = len(df[\"Store\"].unique())\n",
    "print(\"Number of Stores: \" + str(numStores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, we have a pretty large number of stores (around 10% of the stores in the US according to some quick research). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a look at the number of holidays per store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[\"Holiday_Flag\"] == 1].groupby(\"Store\")[\"Holiday_Flag\"].count().hist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like each store has exactly 10 holidays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a look at the average sales per store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Average sales per store differs \n",
    "df.groupby(\"Store\")[\"Weekly_Sales\"].mean().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the average sales per store varies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a look at average temperature per store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Store\")[\"Temperature\"].mean().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of average temperature per store is bimodal with a peak around 52 degrees and another peak around 70 degrees. \n",
    "\n",
    "It seems like the stores are in different regions and/or that the dates for each store span different time frames. \n",
    "\n",
    "Spoiler alert: when you take a look at average CPI per store it becomes clear that there is a temporal difference between stores. However, the geographic difference cannot be asserted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a look at the average CPI per store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Store\")[\"CPI\"].mean().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This supports the assertion that the stores come from different moments in time because CPI is fixed for each day. Thus, if the stores were all overlapping in time we'd see the same average for every store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a look at the average unemployment rate per store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Store\")[\"Unemployment\"].mean().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This once again supports the assertion that the data from these stores don't come from the same period of time. \n",
    "\n",
    "However, it is weird that the average unemployment rate per store and the avg CPI per store don't follow a similar distribution. This might be worth exploring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of findings after exploring the Store column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Observed\n",
    "- Stores aren't aligned in time. That is, the dates of their sales data differ. \n",
    "- Average sales per store differ. Different levels of performance. \n",
    "- Every store has the same number of holidays.\n",
    "- There are 45 stores.\n",
    "\n",
    "##### Questions\n",
    "- Are the stores in different regions?\n",
    "- Why is the distribution of average unemployment rates different from the distribution of average CPI? \n",
    "    - Is unemployment rate local or national? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Date\")[\"Date\"].count().hist()\n",
    "numUnique = len(df[\"Date\"].unique())\n",
    "print(\"The number of unique dates are: \" + str(numUnique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 143 unique dates w/ each date having 45 corresponding instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df[\"Date\"].dt.month)[\"Date\"].count().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have the same amount of data for each month of the year. So this again, supports the assertion that the data for each store is not set in the same time frame.\n",
    "\n",
    "Now, lets take a look at the amount of data we have for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df[\"Date\"].dt.year)[\"Date\"].count().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the most data on sales during 2011, then sales in 2010, and last sales in 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Weekly_Sales\"].hist()\n",
    "mean = df[\"Weekly_Sales\"].mean()\n",
    "stdDev = df[\"Weekly_Sales\"].std()\n",
    "\n",
    "print(\"Mean: \" + str(mean))\n",
    "print(\"Std Dev: \" + str(stdDev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a really weird distribution... why is the distribution this way? Does this have to do with how the sales data was collected, with the way walmart operates it's stores, or some other factor we cannot think of?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the bin edges to align with tick marks\n",
    "bins = [-0.25, 0.25, 0.75, 1.25]\n",
    "\n",
    "non_holiday = df[df['Holiday_Flag'] == 0]\n",
    "holiday = df[df['Holiday_Flag'] == 1]\n",
    "\n",
    "plt.hist(non_holiday['Holiday_Flag'], bins=bins, color='blue', label='Non-Holiday', alpha=0.5)\n",
    "plt.hist(holiday['Holiday_Flag'], bins=bins, color='green', label='Holiday', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Holiday Flag')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Holiday Flag')\n",
    "plt.legend()\n",
    "\n",
    "# Customizing x-axis ticks and labels\n",
    "plt.xticks([0, 0.5, 1], ['Non-Holiday', '', 'Holiday'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this analysis, we can infer that there is a very low percentage of weeks that are holidays. Consequently, holiday weeks, defined as 1, are expected to have a smaller effect on sales compared to holiday weeks. As, their lower holiday weeks vs. vs. holiday weeks in general, will be taking a look at the relationship between holidays and sales further below for stotres 1 - 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Temperature\"].describe())\n",
    "df[\"Temperature\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a large variation in temperatures. This could mean one of three things: \n",
    "- The stores are in different geographic locations. \n",
    "- All the stores are not in different geograhic locations but rather they are all located in a region that sees both temperature extremes a year.\n",
    "- **Climate change** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuel Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View histogram for fuel price\n",
    "df['Fuel_Price'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a bimodal distribution for our fuel prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary statistics\n",
    "mean = df['Fuel_Price'].mean()\n",
    "stdDev = df['Fuel_Price'].std()\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Standard Devation: {stdDev}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today's dollars adjusted for inflation that would be a mean gas price of about $4.70. This unusually high average may affect the generalizability of our ML model / conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Price Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View histogram\n",
    "df['CPI'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have a really weird discrete set of values. I wonder why there seems to be a chunk missing. From my understanding CPI is a continuous index that doesn't simply jump out like that. \n",
    "\n",
    "To dig deeper into why this occured let's look at CPI for each store (it should be roughly the same because the data is from the same time frame but it help determine the cause).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for store 1\n",
    "df[df['Store'] == 1]['CPI'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = df[df['Store'] == 1]['CPI']\n",
    "print(f\"Range: [{frame.min()}, {frame.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks store 1 is continuous in the rough range [210, 223]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View histogram of cpi for store 2\n",
    "df[df['Store'] == 2]['CPI'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = df[df['Store'] == 2]['CPI']\n",
    "print(f\"Range: [{frame.min()}, {frame.max()}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store 2's CPI values seem to be continuous in a very similar range as store 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View histogram of CPI's for store 3\n",
    "df[df['Store'] == 3]['CPI'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = df[df['Store'] == 3]['CPI']\n",
    "print(f\"Range: [{frame.min()}, {frame.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, very similar range of CPI values. So, stores 1, 2, and 3 all have similar CPI ranges and store 4 seems to be an outlier in the CPI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View histogram of CPI values for store 4\n",
    "df[df['Store'] == 4]['CPI'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = df[df['Store'] == 4]['CPI']\n",
    "print(f\"Range: [{frame.min()}, {frame.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suspected, store 4 is completely misasligned with the other stores in terms of it's CPI values. Hence, why we had that huge gap in data in the histogram of ALL CPI values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Unemployment'].hist()\n",
    "\n",
    "print(\"Avg unemployment rate: \" + str(df[\"Unemployment\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have relatively high unemployment rates throughout most of our data. This is an important attribute to note as it may affect the generalizability of our ML Model and/or conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature vs Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempature vs Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use a hypothesis test to figure out whether temperature affects sales.\n",
    "\n",
    "*Null Hypothesis*: The average temperature of the area has no effect on the sales.\n",
    "\n",
    "*Alternative Hypothesis*: The average temperature of the area does have an effect on the sales.\n",
    "\n",
    "Assume that we have a significance level of 0.05.\n",
    "\n",
    "First, let's plot the stores, with their respective average temperature and weekly sales. We'll use a scatter plot, with each dot being a store from the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_avgs = df.groupby(\"Store\").mean(\"Temperature\")\n",
    "\n",
    "temp = store_avgs[\"Temperature\"]\n",
    "sales = store_avgs[\"Weekly_Sales\"]\n",
    "\n",
    "ts = np.vstack([temp,sales])\n",
    "z = sci.stats.gaussian_kde(ts)(ts)\n",
    "\n",
    "fig, plot = plt.subplots()\n",
    "\n",
    "plt.title(\"Temperature vs. Weekly Sales\")\n",
    "plt.xlabel(\"Average Temperature\")\n",
    "plt.ylabel(\"Weekly Sales (in million USD)\")\n",
    "\n",
    "plot.scatter(temp, sales, c=z, s=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the stores are scattered around pretty evenly, with small clusters around the average temperature of 45-55 and 65-75 degree range.\n",
    "\n",
    "Let's check the correlation between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sci.stats.pearsonr(store_avgs[\"Temperature\"], store_avgs[\"Weekly_Sales\"], alternative=\"two-sided\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the pearson correlation coefficient is -0.076, meaning that it is slightly negative. This means that as the average temperature increases, then the weekly sales decrease. Since the p value is larger than our alpha value (0.617), we fail to reject the null hypothesis. In other words, we can see that the average temperature does not have an effect on weekly sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuel Price vs Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a hypothesis test to check if fuel prices have an effect on sales.\n",
    "\n",
    "*Null Hypothesis: Fuel Prices do not have any effect on weekly sales.*\n",
    "\n",
    "*Alternative Hypothesis: Fuel prices do have an effect on weekly sales.*\n",
    "\n",
    "Assume the significance level as 0.05.\n",
    "\n",
    "Let's first create a scatter plot graphing the correlation between fuel price and weekly sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_avgs = df.groupby(\"Store\").mean(\"Fuel_Price\")\n",
    "\n",
    "temp = store_avgs[\"Fuel_Price\"]\n",
    "sales = store_avgs[\"Weekly_Sales\"]\n",
    "\n",
    "ts = np.vstack([temp,sales])\n",
    "z = sci.stats.gaussian_kde(ts)(ts)\n",
    "\n",
    "fig, plot = plt.subplots()\n",
    "\n",
    "plt.title(\"Fuel Price vs. Weekly Sales\")\n",
    "plt.xlabel(\"Average Fuel Price\")\n",
    "plt.ylabel(\"Weekly Sales (in million USD)\")\n",
    "\n",
    "plot.scatter(temp, sales, c=z, s=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuel prices seem divided into three categories of prices, ranging from 3.20, 3.45, and 3.6 USD per gallon. With those three subdivisions, we can see that the weekly sales seem evenly spread out. From inspection, there looks like there's a very, VERY slight downard trend when the fuel price goes up.\n",
    "\n",
    "Let's run a pearson correlation coefficient test to find out the correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sci.stats.pearsonr(store_avgs[\"Fuel_Price\"], store_avgs[\"Weekly_Sales\"], alternative=\"two-sided\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the correlation coefficient is 0.06, which is slightly positive. As fuel prices go up, so do weekly sales. However, this is a very, very small increase, to the point where it isn't significant enough.\n",
    "\n",
    "Since our p value is 0.65, which is way higher than our alpha value of 0.05, we fail to reject the null hypothesis. In other words, fuel price does not have an effect on weekly sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI vs Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use a hypothesis test to figure out whether cpi affects sales.\n",
    "\n",
    "*Null Hypothesis*: The average cpi does no effect on the sales.\n",
    "\n",
    "*Alternative Hypothesis*: The average cpi does have an effect on the sales.\n",
    "\n",
    "Assume that we have a significance level of 0.05.\n",
    "\n",
    "First, let's plot the stores, with their respective average cpi and weekly sales. We'll use a scatter plot, with each dot being a store from the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_avgs = df.groupby(\"Store\").mean(\"CPI\")\n",
    "\n",
    "temp = store_avgs[\"CPI\"]\n",
    "sales = store_avgs[\"Weekly_Sales\"]\n",
    "\n",
    "ts = np.vstack([temp,sales])\n",
    "z = sci.stats.gaussian_kde(ts)(ts)\n",
    "\n",
    "fig, plot = plt.subplots()\n",
    "\n",
    "plt.title(\"CPI vs. Weekly Sales\")\n",
    "plt.xlabel(\"CPI Temperature\")\n",
    "plt.ylabel(\"Weekly Sales (in million USD)\")\n",
    "\n",
    "plot.scatter(temp, sales, c=z, s=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the stores are divided into two groups: some stores cluster around 140 CPI on the left-hand side, while others cluster around 200 CPI on the right-hand side. Interestingly, there appears to be an even distribution of revenue among these points, indicating comparable sales performance across stores despite differences in CPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sci.stats.pearsonr(store_avgs[\"CPI\"], store_avgs[\"Weekly_Sales\"], alternative=\"two-sided\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the Pearson correlation coefficient is -0.0765, indicating a slight negative correlation. This suggests that as the average CPI increases, weekly sales decrease. However, since the p-value is larger than our alpha value (0.617), we fail to reject the null hypothesis. In other words, we can conclude that the average CPI does not have a significant effect on weekly sales. This conclusion is supported by the scatter plot visualization, where no noticeable change in the relationship between average CPI and weekly sales is observed as CPI increases or decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment vs Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to now test if unemployment rates have an effect on the stores' average weekly sales.\n",
    "\n",
    "*Null Hypothesis:* The unemployment rate has no effect on the stores' average weekly sales.\n",
    "\n",
    "*Alternative Hypothesis:* The unemployment rate does have an effect on the stores' average weekly sales.\n",
    "\n",
    "Assume that our significance level is 0.05.\n",
    "\n",
    "We can graph a scatter plot of each store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = store_avgs[\"Unemployment\"]\n",
    "sales = store_avgs[\"Weekly_Sales\"]\n",
    "\n",
    "ts = np.vstack([temp,sales])\n",
    "z = sci.stats.gaussian_kde(ts)(ts)\n",
    "\n",
    "fig, plot = plt.subplots()\n",
    "\n",
    "plt.title(\"Unemployment vs. Weekly Sales\")\n",
    "plt.xlabel(\"Average Unemployment Rate\")\n",
    "plt.ylabel(\"Weekly Sales (in million USD)\")\n",
    "\n",
    "plot.scatter(temp, sales, c=z, s=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the stores' average unemployment rates are between 6-9 percent, with sales being scattered pretty evenly across the board.\n",
    "\n",
    "Let's now check the correlation between the two variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sci.stats.pearsonr(store_avgs[\"Unemployment\"], store_avgs[\"Weekly_Sales\"], alternative=\"two-sided\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the correlation coefficient is -0.112, which is slightly negative. This means that as unemployment rates go up, the weekly sales will go slighly down. Since our p value is 0.46, which is greater than 0.05, we fail to reject the null hypothesis. In other words, the unemployment rate does not have an effect on weekly sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday vs Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be taking a look at the relationship between holidays and sales for stores 1 through 4, as we know from the Holiday flag, there is lower frequency of holiday weeks then non-holiday weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Store 3 with non-Holiday's\n",
    "non_holiday_1 = df[(df['Store'] == 1) & (df['Holiday_Flag'] == 0)].iloc[:140]\n",
    "\n",
    "# Store 4 with holidays\n",
    "holiday_1 = df[(df['Store'] == 1) & (df['Holiday_Flag'] == 1)].iloc[:140]\n",
    "\n",
    "\n",
    "# Plot sales data for Store 1 during non-holiday weeks\n",
    "plt.plot(non_holiday_1.index, non_holiday_1['Weekly_Sales'], color='blue', label='Non-Holiday Weeks')\n",
    "\n",
    "# Plot sales data for Store 1 during holiday weeks\n",
    "plt.plot(holiday_1.index, holiday_1['Weekly_Sales'], color='red', label='Holiday Weeks')\n",
    "\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Weekly Sales (In Millions)')\n",
    "plt.title('Weekly Sales for Store 1')\n",
    "plt.legend()\n",
    "plt.grid(True)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interaction between the sales data during non-holiday and holiday weeks highlights the impact of holidays on consumer behavior and sales activity for Store 1, providing valuable insights for strategic decision-making in retail management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Store 3 with non-Holiday's\n",
    "non_holiday_2 = df[(df['Store'] == 2) & (df['Holiday_Flag'] == 0)].iloc[:140]\n",
    "\n",
    "# Store 4 with holidays\n",
    "holiday_2 = df[(df['Store'] == 2) & (df['Holiday_Flag'] == 1)].iloc[:140]\n",
    "\n",
    "\n",
    "# Plot sales data for Store 1 during non-holiday weeks\n",
    "plt.plot(non_holiday_2.index, non_holiday_2['Weekly_Sales'], color='blue', label='Non-Holiday Weeks')\n",
    "\n",
    "# Plot sales data for Store 1 during holiday weeks\n",
    "plt.plot(holiday_2.index, holiday_2['Weekly_Sales'], color='red', label='Holiday Weeks')\n",
    "\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Weekly Sales (In Millions) ')\n",
    "plt.title('Weekly Sales for Store 2')\n",
    "plt.legend()\n",
    "plt.grid(True)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second store, we notice that there is a significant difference in the total sales amount compared to store 1, which is much higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Store 3 with non-Holiday's\n",
    "non_holiday_3 = df[(df['Store'] == 3) & (df['Holiday_Flag'] == 0)].iloc[:140]\n",
    "\n",
    "# Store 4 with holidays\n",
    "holiday_3 = df[(df['Store'] == 3) & (df['Holiday_Flag'] == 1)].iloc[:140]\n",
    "\n",
    "\n",
    "# Plot sales data for Store 1 during non-holiday weeks\n",
    "plt.plot(non_holiday_3.index, non_holiday_3['Weekly_Sales'], color='blue', label='Non-Holiday Weeks')\n",
    "\n",
    "# Plot sales data for Store 1 during holiday weeks\n",
    "plt.plot(holiday_3.index, holiday_3['Weekly_Sales'], color='red', label='Holiday Weeks')\n",
    "\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Weekly Sales')\n",
    "plt.title('Weekly Sales for Store 3')\n",
    "plt.legend()\n",
    "plt.grid(True)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store 3 consistently reports among the lowest weekly sales figures compared to other stores. Despite occasional spikes during holidays, its sales performance falls significantly short of Stores 1 and 2, which achieve over 3 million and approximately 550k in total sales, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Store 4 with non-Holidays\n",
    "non_holiday_4 = df[(df['Store'] == 4) & (df['Holiday_Flag'] == 0)].iloc[:140]\n",
    "\n",
    "# Store 4 with Holidays\n",
    "holiday__4 = df[(df['Store'] == 4) & (df['Holiday_Flag'] == 1)].iloc[:140]\n",
    "\n",
    "plt.plot(non_holiday_4.index, non_holiday_4['Weekly_Sales'], color='blue', label='Non-Holiday Weeks')\n",
    "\n",
    "plt.plot(holiday__4.index, holiday__4['Weekly_Sales'], color='red', label='Holiday Weeks')\n",
    "\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Weekly Sales(In Millions)')\n",
    "plt.title('Weekly Sales for Store 4')\n",
    "plt.legend()\n",
    "plt.grid(True)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store 4 demonstrates consistent sales performance akin to that of Store 1 and Store 2. This observation suggests that Stores 1, 2, and 4 likely cater to a comparable population size and exhibit similar consumer foot traffic patterns, in contrast to Store 3.\n",
    "\n",
    "Thus, from our analysis of stores 1 through 4, there is a similar spike in sales during holiday weeks, as shown from the visualization. This indicates that these stores will have higher revenue and a greater number of consumers visiting during these holiday weeks. Therefore, during these holiday weeks, these stores should continue to prioritize them since this is when they have the greatest revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, to confirm this, we can create a hypothesis test.\n",
    "\n",
    "*Null Hypothesis: Holiday weeks don't have an effect on weekly sales.*\n",
    "\n",
    "*Alternative Hypothesis: Holiday weeks do have an effect on weekly sales.*\n",
    "\n",
    "Assume our alpha level is 0.05.\n",
    "\n",
    "We can use a t test to determine if the means of sales during holiday weeks vs. non-holiday weeks are different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_diff = df.groupby(\"Holiday_Flag\").mean(\"Weekly_Sales\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "divisions = [\"Non-Holiday\", \"Holiday\"]\n",
    "counts = [holiday_diff[\"Weekly_Sales\"][0], holiday_diff[\"Weekly_Sales\"][1]]\n",
    "\n",
    "ax.bar(divisions, counts, color=[\"tab:red\", \"tab:orange\"])\n",
    "\n",
    "ax.set_ylabel(\"Weekly Sales (in million USD)\")\n",
    "ax.set_title(\"Non-Holiday & Holiday vs. Weekly Sales\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the t test to see if the differences in results are statistically significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday = df[df[\"Holiday_Flag\"] == 1][\"Weekly_Sales\"]\n",
    "no_holiday = df[df[\"Holiday_Flag\"] == 0][\"Weekly_Sales\"]\n",
    "\n",
    "result = sci.stats.ttest_ind(holiday, no_holiday)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our p value is 0.003, which is way lower than the alpha level of 0.05. Through this, we can reject the null hypothesis, meaning that holiday weeks do have an effect on weekly sales! We can also see the differences in the weekly sales for holidays vs. non-holiday weeks in the bar graph above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Month vs. Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a hypothesis test to figure out if the month affects the weekly sales *per store*. Note how it wouldn't make sense if we combined stores' weekly sales for each month, because some stores do way better in general than others. If we did do that, then we wouldn't be able to see the differences in month for a particular store.\n",
    "\n",
    "*Null Hypothesis: The month of the year does not have an effect on weekly sales.*\n",
    "\n",
    "*Alternative Hypothesis: The month of the year does have an effect on weekly sales.*\n",
    "\n",
    "Assume a significance level of 0.05.\n",
    "\n",
    "First of all, let's draw a graph noting the average weekly sales for each month for Store 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "def determine_month(date):\n",
    "    return months[date.month-1]\n",
    "\n",
    "df[\"Month\"] = df[\"Date\"].apply(determine_month)\n",
    "\n",
    "def avg(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "list_of_months = [[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "for index in range(len(months)):\n",
    "    curr_month = []\n",
    "    for ind, item in df[(df[\"Month\"] == months[index]) & (df[\"Store\"] == 1)].iterrows():\n",
    "        curr_month.append(float(item[\"Weekly_Sales\"]))\n",
    "    list_of_months[index] = avg(curr_month)\n",
    "\n",
    "divisions = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "counts = list_of_months\n",
    "\n",
    "ax.bar(divisions, counts, color=[\"tab:red\"])\n",
    "\n",
    "ax.set_ylabel(\"Weekly Sales (in million USD)\")\n",
    "ax.set_title(\"Month vs. Weekly Sales for Store 1\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Store 1 seems to be doing way better in sales during the months of November, December, and February. For every other month, it seems to be doing roughly the same numbers (around 1.5 million USD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's conduct ANOVA tests for every store.\n",
    "\n",
    "Note that we want to see if there exists a difference in the means of weekly sales for each month *for each store*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_results = []\n",
    "\n",
    "def anova_test(store):\n",
    "\n",
    "    january = []\n",
    "    february = []\n",
    "    march = []\n",
    "    april = []\n",
    "    may = []\n",
    "    june = []\n",
    "    july = []\n",
    "    august = []\n",
    "    september = []\n",
    "    october = []\n",
    "    november = []\n",
    "    december = []\n",
    "\n",
    "    list_of_months = [january, february, march, april, may, june, july, august, september, october, november, december]\n",
    "\n",
    "    for index in range(len(months)):\n",
    "        for ind, item in df[(df[\"Month\"] == months[index]) & (df[\"Store\"] == store)].iterrows():\n",
    "            list_of_months[index].append(float(item[\"Weekly_Sales\"]))\n",
    "\n",
    "    result = sci.stats.f_oneway(january, february, march, april, may, june, july, august, september, october, november, december)\n",
    "    \n",
    "    print(\"Store \" + str(store) + \" test pvalue: \" + str(result.pvalue))\n",
    "    p_value_results.append(result.pvalue)\n",
    "\n",
    "for num in range(1, 46):\n",
    "    anova_test(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some stores (Store 42, 43, 44, etc...) exibit higher p values upon inspection, going up to 0.66, which would allow us to fail to reject the null hypothesis. However, for the most part, most stores exibit very low p values, way lower than our significance level. This would mean that we'd have to reject the null hypothesis. Let's see how many stores had a result lower than 0.05, and those who had a result higher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_less = 0\n",
    "num_more = 0\n",
    "\n",
    "for value in p_value_results:\n",
    "    if value <= 0.05:\n",
    "        num_less = num_less + 1\n",
    "    elif value > 0.05:\n",
    "        num_more = num_more + 1\n",
    "\n",
    "print(\"Number of stores with p values less than 0.05: \" + str(num_less))\n",
    "print(\"Number of stores with p values more than 0.05: \" + str(num_more))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that for the most part, the months of the year do affect the average sales per store."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
